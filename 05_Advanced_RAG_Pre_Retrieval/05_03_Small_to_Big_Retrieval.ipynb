{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install llama-index==0.10.25 llama-index-embeddings-fastembed qdrant-client llama-index-vector-stores-qdrant llama-index-llms-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "sys.path.append('../helpers')\n",
    "\n",
    "from utils import setup_llm, setup_embed_model, setup_vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO_API_KEY = os.environ['CO_API_KEY'] or getpass(\"Enter your Cohere API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_URL = os.environ['QDRANT_URL'] or getpass(\"Enter your Qdrant URL:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_API_KEY = os.environ['QDRANT_API_KEY'] or  getpass(\"Enter your Qdrant API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.settings import Settings\n",
    "from utils import setup_llm, setup_embed_model\n",
    "\n",
    "setup_llm(api_key=CO_API_KEY)\n",
    "\n",
    "setup_embed_model(provider=\"fastembed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_documents_from_docstore\n",
    "\n",
    "senpai_documents = get_documents_from_docstore(\"../data/words-of-the-senpais\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "eval_dataset = load_dataset(\"harpreetsahota/LI_Learning_RAG_Eval_Set\", split='train')\n",
    "\n",
    "eval_dataset = eval_dataset.filter(lambda x: x['question_groundedness_score'] is not None and x['question_groundedness_score'] >= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[42].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸªŸ`SentenceWindowNodeParser`\n",
    "\n",
    "The `SentenceWindowNodeParser` is unique in that it focuses on individual sentences while also capturing the surrounding context.  This is particularly useful for tasks where understanding the broader context of a sentence is useful.\n",
    "\n",
    "### How it Works\n",
    "\n",
    "1. **Sentence Splitting:** \n",
    "\n",
    "    *   Similar to `SentenceSplitter`, it first divides the document into individual sentences using a sentence tokenizer (defaults to [`PunktSentenceTokenizer`](https://www.nltk.org/api/nltk.tokenize.PunktSentenceTokenizer.html) from the `nltk` library).\n",
    "\n",
    "2. **Window Creation:**\n",
    "    *   For each sentence (node), it gathers a \"window\" of surrounding sentences based on the specified `window_size`. \n",
    "\n",
    "    *   This window is stored in the node's metadata under the `window_metadata_key`.\n",
    "\n",
    "3. **Metadata Management:**\n",
    "\n",
    "    *   The original sentence text is also stored in the metadata under `original_text_metadata_key`.\n",
    "\n",
    "    *   Importantly, both the window and original text are excluded from being seen by the embedding model and LLM.\n",
    "\n",
    "### Arguments you need to know\n",
    "\n",
    "*   **`window_size`**: Controls the number of sentences to include before and after the central sentence in the window.\n",
    "\n",
    "*   **`window_metadata_key`**: The key used to store the window text in the node's metadata.\n",
    "\n",
    "*   **`original_text_metadata_key`**: The key used to store the original sentence text in the metadata.\n",
    "\n",
    "### Usage Example\n",
    "\n",
    "```python\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "parser = SentenceWindowNodeParser(window_size=2)\n",
    "\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "```\n",
    "\n",
    "### When to Use SentenceWindowNodeParser\n",
    "\n",
    "*   **Tasks requiring sentence-level understanding with context:** \n",
    "    *   Question answering, summarization, or sentiment analysis where the surrounding sentences provide valuable context.\n",
    "\n",
    "*   **Fine-grained control over embedding scope:** \n",
    "    *   Creating embeddings that focus on the specific meaning of a sentence within its local context.\n",
    "    \n",
    "*   **Combining with MetadataReplacementNodePostProcessor:**\n",
    "    *   Replacing the original sentence with its surrounding window before sending it to the LLM, allowing the model to consider the broader context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "SentenceWindowNodeParser(window_size=2).build_window_nodes_from_documents([documents[42]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentenceWindowNodeParser(window_size=3).get_nodes_from_documents([documents[42]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_window_splitter(window, documents):\n",
    "    splitter = SentenceSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=16,\n",
    "        )\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lil_llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
