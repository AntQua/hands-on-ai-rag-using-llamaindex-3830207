{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install llama-index==0.10.37 datasets llama-index-embeddings-openai llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you should install the following packages to your environment:\n",
    "\n",
    "`pip install datasets`\n",
    "\n",
    "`pip install llama-index-embeddings-fastembed`\n",
    "\n",
    "`pip install llama-index-llms-mistralai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append('../helpers')\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY'] or getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using OpenAI here because Cohere has rate limits for it's free tier. You don't need to run this code yourself if you don't want to incur costs from OpenAI. I'll upload the dataset to the Hugging Face Hub and I'll show you how to download it from there when we need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /opt/conda/envs/lil_llama_index/lib/python3.10/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already cleaned up our data before. Recall that we've persisted the `Document` objects to disk using a Docstore in such a way that each Document object represents cleaned text from a page of a book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-05 10:10:42.470\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfastembed.embedding\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[33m\u001b[1mDefaultEmbedding, FlagEmbedding, JinaEmbedding are deprecated.Use from fastembed import TextEmbedding instead.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from utils import get_documents_from_docstore\n",
    "\n",
    "documents = get_documents_from_docstore(\"../data/words-of-the-senpais\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a set of `Documents` for the evaluation set\n",
    "\n",
    "- üìö **`group_documents_by_author`**: A utility function that sorts a collection of douments into groups based on who wrote them.\n",
    "\n",
    "- üóÇÔ∏è **How It Works**: It creates a  dictionary where each author's name is linked to all the documents they've written.\n",
    "  - Starts with an empty dictionary ready to be filled with author-document pairs.\n",
    "  - Goes through each document, checking the author's name and adding the document under the appropriate author in the dictionary.\n",
    "  - If a document doesn't list an author, it skips adding that document with a warning note.\n",
    "\n",
    "- üìù **Input**: Takes a list of `Document` objects, each with metadata that includes the `author` field (the name of its author).\n",
    "\n",
    "- üîñ **Output**: Outputs a dictionary that groups all the documents by their respective authors.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from utils import group_documents_by_author\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "documents_by_author = group_documents_by_author(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- üìö **`sample_documents`**: Picks a set number of documents randomly from each author's collection within a grouped dictionary.\n",
    "\n",
    "- üé≤ **Sampling Logic**: It tries to get a specific number of documents for each author. If an author doesn't have enough documents, it alerts you.\n",
    "  - Begins with an empty list for storing selected samples.\n",
    "  - Loops through each author, considers only docs with >500 characters, checking if there are enough documents to fulfill the sampling requirement.\n",
    "  - Randomly selects the desired number of documents from those available, adding them to the overall sample list.\n",
    "  - Issues a warning if the documents under an author are too few to meet the sampling number.\n",
    "\n",
    "- üìù **Input**: Receives a dictionary where authors are keys and values are lists of their documents, along with an optional number of documents to sample per author.\n",
    "\n",
    "- üîñ **Output**: Outputs a list of randomly chosen documents from across all authors, sticking to the specified number per author when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sample_documents\n",
    "\n",
    "docs_for_eval_set = sample_documents(documents_by_author, num_samples=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author 'Naval Ravikant' has 25 documents.\n",
      "Author 'Balaji Srinivasan' has 25 documents.\n",
      "Author 'Paul Graham' has 25 documents.\n",
      "Author 'Nassim Nicholas Taleb' has 25 documents.\n",
      "Author 'Seneca' has 25 documents.\n",
      "Author 'Bruce Lee' has 25 documents.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_documents_by_author(documents):\n",
    "    \"\"\"\n",
    "    Count the number of documents each author has in a list of document objects.\n",
    "\n",
    "    :param documents: List of document objects with metadata containing 'author'.\n",
    "    :return: A Counter object with authors as keys and counts of their documents as values.\n",
    "    \"\"\"\n",
    "    # Extract the author from each document's metadata and count occurrences\n",
    "    author_counts = Counter(doc.metadata['author'] for doc in documents if 'author' in doc.metadata)\n",
    "    return author_counts\n",
    "\n",
    "author_counts = count_documents_by_author(docs_for_eval_set)\n",
    "for author, count in author_counts.items():\n",
    "    print(f\"Author '{author}' has {count} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_for_eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ingest \n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "splitter = TokenTextSplitter(\n",
    "    chunk_size = 256,\n",
    "    chunk_overlap = 32\n",
    ")\n",
    "\n",
    "transformations = [splitter]\n",
    "\n",
    "docs_for_eval_set = ingest(documents = docs_for_eval_set, transformations = transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_for_eval_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create an evaluation set using custom prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to write a question given a context. Your question must be in the form of an adult mentee seeking advice \n",
      "from a trusted mentor. Formulate your question in the same style as questions users could ask in a search engine. Your question must be \n",
      "answerable with a specific, concise piece of information from the context. \n",
      "\n",
      "The context is below:\n",
      "----------------------\n",
      "{context_str}\n",
      "----------------------\n",
      "\n",
      "Your question MUST be short, clear, and based on the essence of the context. DO NOT use any qualifiers, relative clauses, or introductory modifiers.  \n",
      "Keep your question short and to the point. Ask your question using the first person perspective, in the form of a student seeking advice from a trusted mentor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.prompts.base import PromptTemplate\n",
    "from prompts import QUESTION_GEN_PROMPT\n",
    "print(QUESTION_GEN_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_GEN_PROMPT_TEMPLATE = PromptTemplate(QUESTION_GEN_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I work my way up to higher leverage, more accountability, and specific knowledge without risking ruin or getting into legal trouble?\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "prompt = QUESTION_GEN_PROMPT_TEMPLATE.format(context_str=docs_for_eval_set[10].get_content()) \n",
    "\n",
    "response = llm.complete(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ + ‚ùìGenerate questions from context\n",
    "\n",
    "We'll use GPT-3.5-Turbo to generate questions from our `Documents`\n",
    "\n",
    "Here's what the function below is doing:\n",
    "\n",
    "- Initialize an empty dictionary results to store the responses and contexts.\n",
    "\n",
    "- Iterate through each document doc in `docs_for_eval_set`.\n",
    "\n",
    "- For each document, we generate the prompt using `QUESTION_GEN_PROMPT_TEMPLATE` and the document's content.\n",
    "\n",
    "- Get the response from the LLM using `question_gen_llm.complete(prompt)`.\n",
    "\n",
    "- Store the response as the key, and the document's content as the value with the key \"context\" in the results dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "questions = []\n",
    "\n",
    "for doc in docs_for_eval_set:\n",
    "    result_dict = {}\n",
    "    context = doc.get_content()\n",
    "    prompt = QUESTION_GEN_PROMPT_TEMPLATE.format(context_str=context)\n",
    "    response = llm.complete(prompt)\n",
    "    result_dict['question'] = response.text\n",
    "    result_dict[\"context\"] =  context\n",
    "    questions.append(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'How can I leverage code to multiply my efforts without needing permission or money from others?',\n",
       "  'context': 'This includes books, media, movies, and code. Code is probably the most powerful form of permissionless leverage. All you need is a computeryou dont need anyones permission. Forget rich versus poor, white-collar versus blue. Its now leveraged versus un-leveraged. The most interesting and the most important form of leverage is the idea of products that have no marginal cost of replication. This is the new form of leverage. This was only invented in the last few hundred years. It started with the printing press. It accelerated with broadcast media, and now its really blown up with the internet and with coding. Now, you can multiply your efforts without involving other humans and without needing money from other humans. This book is a form of leverage. Long ago, I would have had to sit in a lecture hall and lecture each of you personally. I would have maybe reached a few hundred people, and that would have been that. This newest form of leverage is where all the new fortunes are made, all the new billionaires. For the last generation,'},\n",
       " {'question': 'How can I leverage code or media to build a fortune like the new generation of billionaires?',\n",
       "  'context': 'and that would have been that. This newest form of leverage is where all the new fortunes are made, all the new billionaires. For the last generation, fortunes were made by capital. The people who made fortunes were the Warren Buffetts of the world. But the new generations fortunes are all made through code or media. Joe Rogan making $50 million to $100 million a year from his podcast. Youre going to have PewDiePie. I dont know how much money hes rolling in, but hes bigger than the news. And of course, theres Jeff Bezos, Mark Zuckerberg, Larry Page,'},\n",
       " {'question': 'How can I determine whether to fix a problem or outsource a task based on my hourly rate?',\n",
       "  'context': 'There is no skill called business. Avoid business magazines and business classes. Study microeconomics, game theory, psychology, persuasion, ethics, mathematics, and computers. Reading is faster than listening. Doing is faster than watching. You should be too busy to do coffee while still keeping an uncluttered calendar. Set and enforce an aspirational personal hourly rate. If fixing a problem will save less than your hourly rate, ignore it. If outsourcing a task will cost less than your hourly rate, outsource it. Work as hard as you can. Even though who you work with and what you work on are more important than how hard you work.'},\n",
       " {'question': 'How can I improve my decision-making skills by collecting mental models?',\n",
       "  'context': 'technology and large workforces and capital, our decisions are leveraged more and more. If you can be more right and more rational, youre going to get nonlinear returns in your life. I love the blog Farnam Street because it really focuses on helping you be more accurate, an overall better decision-maker. Decision-making is everything. The more you know, the less you diversify. COLLECT MENTAL MODELS During decision-making, the brain is a memory prediction machine. A lousy way to do memory prediction is X happened in the past, therefore X will happen in the future. Its too based on specific circumstances. What you want is principles. You want mental models. The best mental models I have found came through evolution, game theory, and Charlie Munger. Charlie Munger is Warren Buffetts partner. Very good investor. He has tons and tons of great mental models. Author and trader Nassim Taleb has great mental models. Benjamin Franklin had great mental models. I basically load my head full of mental models. I use my'},\n",
       " {'question': 'How can I use tweets as maxims to compress my learnings and recall them effectively?',\n",
       "  'context': 'Author and trader Nassim Taleb has great mental models. Benjamin Franklin had great mental models. I basically load my head full of mental models. I use my tweets and other peoples tweets as maxims that help compress my own learnings and recall them. The brain space is finiteyou have finite neuronsso you can almost think'},\n",
       " {'question': 'How can I ensure I am dealing with reality when making decisions?',\n",
       "  'context': 'The really smart thinkers are clear thinkers. They understand the basics at a very, very fundamental level. I would rather understand the basics really well than memorize all kinds of complicated concepts I cant stitch together and cant rederive from the basics. If you cant rederive concepts from the basics as you need them, youre lost. Youre just memorizing. The advanced concepts in a field are less proven. We use them to signal insider knowledge, but wed be better off nailing the basics. Clear thinkers appeal to their own authority. Part of making effective decisions boils down to dealing with reality. How do you make sure youre dealing with reality when youre making decisions? By not having a strong sense of self or judgments or mind presence. The monkey mind will always respond with this regurgitated emotional response to what it thinks the world should be. Those desires will cloud your reality. This happens a lot of times when people are mixing politics and business. The number one thing clouding us from being able to see reality is we have preconceived notions of the way'},\n",
       " {'question': \"How can I avoid being blinded by preconceived notions and see my business's reality clearly before it fails?\",\n",
       "  'context': 'times when people are mixing politics and business. The number one thing clouding us from being able to see reality is we have preconceived notions of the way it should be. One definition of a moment of suffering is the moment when you see things exactly the way they are. This whole time, youve been convinced your business is doing great, and really, youve ignored the signs its not doing well. Then, your business fails,'},\n",
       " {'question': 'How can I become the best in the world at what I do?',\n",
       "  'context': 'became extremely successful. You just had to give them a long enough timescale. It never happens in the timescale you want, or they want, but it does happen. Apply specific knowledge with leverage and eventually, you will get what you deserve. It takes timeeven once you have all of these pieces in place, there is an indeterminate amount of time you have to put in. If youre counting, youll run out of patience before success actually arrives. Everybody wants to get rich immediately, but the world is an efficient place; immediate doesnt work. You do have to put in the time. You do have to put in the hours, and so I think you have to put yourself in the position with the specific knowledge, with accountability, with leverage, with the authentic skill set you have, to be the best in the world at what you do. You have to enjoy it and keep doing it, keep doing it, and keep doing it. Dont keep track, and dont keep count because if you do, you will run out of time.'},\n",
       " {'question': 'How can I truly learn something?',\n",
       "  'context': 'doing it, keep doing it, and keep doing it. Dont keep track, and dont keep count because if you do, you will run out of time. The most common bad advice I hear is: Youre too young. Most of history was built by young people. They just got credit when they were older. The only way to truly learn something is by doing it. Yes, listen to guidance. But dont wait.'},\n",
       " {'question': 'How can I build a successful technology and real estate company with high-risk, high-reward potential?',\n",
       "  'context': 'Obviously, not a single person may know this. You may pull a team together to do it where each have different skill sets, but that combined entity would have specific knowledge in technology and in real estate. It would have massive accountability because that companys name would be a very high-risk, high-reward effort attached to the whole thing, and people would devote their lives to it and take on significant risk. It would have leverage in code with lots of developers. It would have capital with investors putting money in and the founders own capital. It would have some of the highest-quality labor you can find, which is high-quality engineers, designers, and marketers who are working on the company. Then, you may end up with a Trulia, Redfin, or Zillow company, and then the upside could potentially be in the billions of dollars, or the hundreds of millions of dollars. Each level has increasing leverage, increasing accountability, increasingly specific knowledge. Youre adding in moneybased leverage on top of labor-based leverage. Adding in code-based leverage on top of'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ + üí¨ Create answers using generated question and context\n",
    "\n",
    "Using GPT-3.5-Turbo (to keep costs down, you can of course use GPT-4-Turbo), we'll generate answers using the questions we just created plus the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a trusted mentor to an adult mentee. Your mentee comes to you with a challenging question. \n",
      "\n",
      "Below is the question:\n",
      "\n",
      "----------------------\n",
      "{query_str}\n",
      "----------------------\n",
      "\n",
      "You have some raw thoughts which you must use to formulate an answer to your mentee's question. Below are your thoughts:\n",
      "\n",
      "----------------------\n",
      "{context_str}\n",
      "----------------------\n",
      "\n",
      "Reflect on the question and your raw thoughts, then answer your mentee's question. Your response must be based on your raw thoughts, not on prior knowledge.\n",
      "\n",
      "When answering DO NOT use any qualifiers, relative clauses, or introductory modifiers in your answer. Provide your answer question using the second person\n",
      "perspective, speaking directly to your mentee. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from prompts import ANSWER_GEN_PROMPT\n",
    "\n",
    "print(ANSWER_GEN_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER_GEN_PROMPT_TEMPLATE = PromptTemplate(ANSWER_GEN_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigate the onset of desire and long-range planning during puberty by focusing on building your identity and ego to achieve what you want in the real world.\n"
     ]
    }
   ],
   "source": [
    "prompt = ANSWER_GEN_PROMPT_TEMPLATE.format(query_str=questions[42]['question'], context_str=questions[42]['context']) \n",
    "\n",
    "response = llm.complete(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in questions:\n",
    "    prompt = ANSWER_GEN_PROMPT_TEMPLATE.format(query_str=question['question'], context_str=question['context']) \n",
    "    response = llm.complete(prompt)\n",
    "    question['answer'] = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'How can I leverage code to multiply my efforts without needing permission or money from others?',\n",
       "  'context': 'This includes books, media, movies, and code. Code is probably the most powerful form of permissionless leverage. All you need is a computeryou dont need anyones permission. Forget rich versus poor, white-collar versus blue. Its now leveraged versus un-leveraged. The most interesting and the most important form of leverage is the idea of products that have no marginal cost of replication. This is the new form of leverage. This was only invented in the last few hundred years. It started with the printing press. It accelerated with broadcast media, and now its really blown up with the internet and with coding. Now, you can multiply your efforts without involving other humans and without needing money from other humans. This book is a form of leverage. Long ago, I would have had to sit in a lecture hall and lecture each of you personally. I would have maybe reached a few hundred people, and that would have been that. This newest form of leverage is where all the new fortunes are made, all the new billionaires. For the last generation,',\n",
       "  'answer': 'Use code to create products that can be replicated at no additional cost. This form of leverage allows you to multiply your efforts without needing permission or money from others. Focus on developing products that can be easily distributed and scaled using the power of the internet and coding. This is where new fortunes are made and where you can truly maximize your impact without relying on external resources.'},\n",
       " {'question': 'How can I leverage code or media to build a fortune like the new generation of billionaires?',\n",
       "  'context': 'and that would have been that. This newest form of leverage is where all the new fortunes are made, all the new billionaires. For the last generation, fortunes were made by capital. The people who made fortunes were the Warren Buffetts of the world. But the new generations fortunes are all made through code or media. Joe Rogan making $50 million to $100 million a year from his podcast. Youre going to have PewDiePie. I dont know how much money hes rolling in, but hes bigger than the news. And of course, theres Jeff Bezos, Mark Zuckerberg, Larry Page,',\n",
       "  'answer': 'To build a fortune like the new generation of billionaires, you need to leverage code or media. Look at Joe Rogan, PewDiePie, Jeff Bezos, Mark Zuckerberg, and Larry Page. They have all made their fortunes through code or media. Focus on creating valuable content and utilizing technology to reach a wide audience. This is where the new fortunes are being made.'},\n",
       " {'question': 'How can I determine whether to fix a problem or outsource a task based on my hourly rate?',\n",
       "  'context': 'There is no skill called business. Avoid business magazines and business classes. Study microeconomics, game theory, psychology, persuasion, ethics, mathematics, and computers. Reading is faster than listening. Doing is faster than watching. You should be too busy to do coffee while still keeping an uncluttered calendar. Set and enforce an aspirational personal hourly rate. If fixing a problem will save less than your hourly rate, ignore it. If outsourcing a task will cost less than your hourly rate, outsource it. Work as hard as you can. Even though who you work with and what you work on are more important than how hard you work.',\n",
       "  'answer': 'Determine whether to fix a problem or outsource a task based on whether it will save more or cost less than your hourly rate. Set and enforce an aspirational personal hourly rate. Work as hard as you can.'},\n",
       " {'question': 'How can I improve my decision-making skills by collecting mental models?',\n",
       "  'context': 'technology and large workforces and capital, our decisions are leveraged more and more. If you can be more right and more rational, youre going to get nonlinear returns in your life. I love the blog Farnam Street because it really focuses on helping you be more accurate, an overall better decision-maker. Decision-making is everything. The more you know, the less you diversify. COLLECT MENTAL MODELS During decision-making, the brain is a memory prediction machine. A lousy way to do memory prediction is X happened in the past, therefore X will happen in the future. Its too based on specific circumstances. What you want is principles. You want mental models. The best mental models I have found came through evolution, game theory, and Charlie Munger. Charlie Munger is Warren Buffetts partner. Very good investor. He has tons and tons of great mental models. Author and trader Nassim Taleb has great mental models. Benjamin Franklin had great mental models. I basically load my head full of mental models. I use my',\n",
       "  'answer': 'Improve decision-making skills by collecting mental models. Load your head full of principles and mental models from sources like Farnam Street, Charlie Munger, Nassim Taleb, and Benjamin Franklin. Focus on evolving your memory prediction machine with these models to make more accurate and rational decisions.'},\n",
       " {'question': 'How can I use tweets as maxims to compress my learnings and recall them effectively?',\n",
       "  'context': 'Author and trader Nassim Taleb has great mental models. Benjamin Franklin had great mental models. I basically load my head full of mental models. I use my tweets and other peoples tweets as maxims that help compress my own learnings and recall them. The brain space is finiteyou have finite neuronsso you can almost think',\n",
       "  'answer': 'Use tweets as maxims to compress your learnings and recall them effectively. Load your head full of mental models from great thinkers like Nassim Taleb and Benjamin Franklin. Use tweets as maxims to help compress your own learnings and recall them easily. Remember, brain space is finite, so make the most of it by utilizing these maxims.'},\n",
       " {'question': 'How can I ensure I am dealing with reality when making decisions?',\n",
       "  'context': 'The really smart thinkers are clear thinkers. They understand the basics at a very, very fundamental level. I would rather understand the basics really well than memorize all kinds of complicated concepts I cant stitch together and cant rederive from the basics. If you cant rederive concepts from the basics as you need them, youre lost. Youre just memorizing. The advanced concepts in a field are less proven. We use them to signal insider knowledge, but wed be better off nailing the basics. Clear thinkers appeal to their own authority. Part of making effective decisions boils down to dealing with reality. How do you make sure youre dealing with reality when youre making decisions? By not having a strong sense of self or judgments or mind presence. The monkey mind will always respond with this regurgitated emotional response to what it thinks the world should be. Those desires will cloud your reality. This happens a lot of times when people are mixing politics and business. The number one thing clouding us from being able to see reality is we have preconceived notions of the way',\n",
       "  'answer': 'Focus on understanding the basics really well and being able to rederive concepts from them. Clear your mind of strong judgments and desires that can cloud your perception of reality. Avoid mixing politics and business to prevent preconceived notions from affecting your decision-making process. Trust your own authority and appeal to it when making decisions.'},\n",
       " {'question': \"How can I avoid being blinded by preconceived notions and see my business's reality clearly before it fails?\",\n",
       "  'context': 'times when people are mixing politics and business. The number one thing clouding us from being able to see reality is we have preconceived notions of the way it should be. One definition of a moment of suffering is the moment when you see things exactly the way they are. This whole time, youve been convinced your business is doing great, and really, youve ignored the signs its not doing well. Then, your business fails,',\n",
       "  'answer': \"Focus on seeing things exactly as they are without letting preconceived notions cloud your judgment. Look for signs that your business may not be doing well and address them before it's too late. Stay open-minded and be willing to accept the reality of the situation, even if it's difficult. Trust your instincts and be proactive in making necessary changes to avoid failure.\"},\n",
       " {'question': 'How can I become the best in the world at what I do?',\n",
       "  'context': 'became extremely successful. You just had to give them a long enough timescale. It never happens in the timescale you want, or they want, but it does happen. Apply specific knowledge with leverage and eventually, you will get what you deserve. It takes timeeven once you have all of these pieces in place, there is an indeterminate amount of time you have to put in. If youre counting, youll run out of patience before success actually arrives. Everybody wants to get rich immediately, but the world is an efficient place; immediate doesnt work. You do have to put in the time. You do have to put in the hours, and so I think you have to put yourself in the position with the specific knowledge, with accountability, with leverage, with the authentic skill set you have, to be the best in the world at what you do. You have to enjoy it and keep doing it, keep doing it, and keep doing it. Dont keep track, and dont keep count because if you do, you will run out of time.',\n",
       "  'answer': \"Put in the time, apply specific knowledge with leverage, and keep doing what you love without keeping track. That's how you become the best in the world at what you do.\"},\n",
       " {'question': 'How can I truly learn something?',\n",
       "  'context': 'doing it, keep doing it, and keep doing it. Dont keep track, and dont keep count because if you do, you will run out of time. The most common bad advice I hear is: Youre too young. Most of history was built by young people. They just got credit when they were older. The only way to truly learn something is by doing it. Yes, listen to guidance. But dont wait.',\n",
       "  'answer': \"Just keep doing it. Don't keep track or count. The only way to truly learn something is by doing it. Listen to guidance, but don't wait.\"},\n",
       " {'question': 'How can I build a successful technology and real estate company with high-risk, high-reward potential?',\n",
       "  'context': 'Obviously, not a single person may know this. You may pull a team together to do it where each have different skill sets, but that combined entity would have specific knowledge in technology and in real estate. It would have massive accountability because that companys name would be a very high-risk, high-reward effort attached to the whole thing, and people would devote their lives to it and take on significant risk. It would have leverage in code with lots of developers. It would have capital with investors putting money in and the founders own capital. It would have some of the highest-quality labor you can find, which is high-quality engineers, designers, and marketers who are working on the company. Then, you may end up with a Trulia, Redfin, or Zillow company, and then the upside could potentially be in the billions of dollars, or the hundreds of millions of dollars. Each level has increasing leverage, increasing accountability, increasingly specific knowledge. Youre adding in moneybased leverage on top of labor-based leverage. Adding in code-based leverage on top of',\n",
       "  'answer': 'To build a successful technology and real estate company with high-risk, high-reward potential, you need to assemble a team with diverse skill sets in technology and real estate. This team must have massive accountability and be willing to take on significant risk. You will need leverage in code with developers, capital from investors and founders, and high-quality labor such as engineers, designers, and marketers. By combining these elements, you can potentially create a company like Trulia, Redfin, or Zillow with the potential for billions of dollars in upside. Each level of leverage and accountability will increase your chances of success.'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßê How good are our questions?\n",
    "\n",
    "I suppose you could do this part before generating answers, if you wanted to...But we'll do it now.\n",
    "\n",
    "Here we're going to use GPT-4-Turbo to judge how good the questions is based on the context. We'll write a prompt that does this and score each question on a scale of 1-5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_llm = OpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given context and a question. Provide a 'total rating' from 1 to 5 indicating \n",
      "the extent to which the question can be answered clearly using the context. 1 = not answerable, 5 = clearly answerable\n",
      "\n",
      "Format your response as:\n",
      "\n",
      "Evaluation: (rationale)\n",
      "Total rating: (a number in the range 1-5)\n",
      "\n",
      "Content and question are below:\n",
      "----------------------\n",
      "Context: {context_str}\n",
      "Question: {query_str}\n",
      "----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from prompts import GROUNDEDNESS_PROMPT\n",
    "\n",
    "print(GROUNDEDNESS_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUNDEDNESS_PROMPT_TEMPLATE = PromptTemplate(GROUNDEDNESS_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: The context provides a brief explanation of puberty as the onset of desire and the beginning of long-range planning, but it does not offer specific guidance or strategies on how to navigate these changes. The question asks for advice on navigating these aspects of puberty, which is not directly addressed in the context provided.\n",
      "\n",
      "Total rating: 2\n"
     ]
    }
   ],
   "source": [
    "prompt = GROUNDEDNESS_PROMPT_TEMPLATE.format(query_str=questions[42]['question'], context_str=questions[42]['context']) \n",
    "\n",
    "response = critic_llm.complete(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in questions:\n",
    "    prompt = GROUNDEDNESS_PROMPT_TEMPLATE.format(query_str=question['question'], context_str=question['context']) \n",
    "    response = critic_llm.complete(prompt)\n",
    "    response_string = response.text\n",
    "    try:\n",
    "        score_as_int = int(response_string.split(\"Total rating: \")[-1].strip())\n",
    "        score_rational = response_string.split(\"Total rating: \")[-2].split(\"Evaluation: \")[1]\n",
    "        question['question_groundedness_score'] = score_as_int\n",
    "        question['question_groundedness_score_rationale'] = score_rational\n",
    "    except Exception as e:\n",
    "        question['question_groundedness_score'] = None\n",
    "        question['question_groundedness_score_rationale'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'How can I become a good teacher who functions as a pointer to truth, rather than a giver of truth?',\n",
       "  'context': 'Teaching Teaching requires a sensitive mind with great flexibility. Above all, a teacher doesnotdependonamethodanddrillsystematicroutines;instead,hestudies eachindividualstudentandawakenshimtoexplorehimself,bothinternallyand externally,andultimatelyintegratehimselfwithhisbeing.Suchteaching,which is really no teaching, requires a sensitive mind with great flexibility and is difficulttocomebynowadays. Ateacherisapointertotruth,notagiveroftruth.-Ateacher,agoodteacher thatis,functionsasapointertotruth,butnotagiveroftruth.Heemploysa minimumofformtoleadhisstudenttotheformless.Furthermore,hepointsout theimportanceofbeingabletoenteramoldwithoutbeingimprisonedbyit,or tofollowtheprincipleswithoutbeingboundbythem. Theteachercannotbefixedinaroutine.-Agoodteachercannotbefixedina routine.Hemustnotimposehisstudenttofitalifelesspattern,apreformulation.',\n",
       "  'answer': 'To become a good teacher who functions as a pointer to truth, rather than a giver of truth, you must have a sensitive mind with great flexibility. You should study each individual student and awaken them to explore themselves internally and externally, ultimately integrating themselves with their being. Remember, you are not a giver of truth, but a pointer to truth. Use a minimum of form to lead your students to the formless and emphasize the importance of entering a mold without being imprisoned by it. Do not be fixed in a routine and do not impose lifeless patterns on your students. Be a guide, not a dictator.',\n",
       "  'question_groundedness_score': 5,\n",
       "  'question_groundedness_score_rationale': 'The context provides a detailed description of what it means to be a good teacher who functions as a pointer to truth rather than a giver of truth. It emphasizes the importance of flexibility, sensitivity, and the ability to guide students to explore and integrate themselves. The context also highlights the need for teachers to avoid rigid routines and to lead students to understand principles without being bound by them. This directly addresses the question of how to become such a teacher.\\n\\n'},\n",
       " {'question': 'How can I awaken my awareness of the cause and effect of my problems?',\n",
       "  'context': 'routine.Hemustnotimposehisstudenttofitalifelesspattern,apreformulation. Themostdifficultthingtoteach.-Agoodteacherprotectshispupilsfromhis owninfluence.Itiseasytoteachonetobeskillful,butitisdifficulttoteachhim hisownattitude.Eachmomentduringteachingrequiresafullalertandsensitive mindthatisconstantlyadjustingandconstantlychanging. Put my words to the test. - Remember, I am no teacher; I can merely be a signpostforatravelerwhoislost.Itisuptoyoutodecideonthedirection.AllI canofferisanexperiencebutneveraconclusion,soevenwhatIhavesaidneeds tobethoroughlyexaminedbyyou.Imightbeabletohelpyoutodiscoverand examineyourproblembyawakeningyourawarenessoftheircauseandeffect,',\n",
       "  'answer': \"Awaken your awareness by constantly adjusting and changing your mindset. Protect yourself from imposing lifeless patterns and be open to examining the cause and effect of your problems. Remember, I can guide you, but the direction is up to you. It's your responsibility to thoroughly examine and discover the root of your issues.\",\n",
       "  'question_groundedness_score': 3,\n",
       "  'question_groundedness_score_rationale': \"The context discusses the role of a teacher in guiding students to develop their own attitudes and awareness, rather than imposing a fixed pattern or conclusion. It suggests that teaching involves helping students discover and examine their problems by awakening their awareness of cause and effect. However, the context does not provide specific methods or steps on how to awaken one's awareness, making it somewhat abstract and indirect in addressing the question.\\n\\n\"},\n",
       " {'question': 'How can I attain happiness in my work?',\n",
       "  'context': \"Two ways of making a good living. - There are two ways of making a good living. One is the result of hard working, and the other, the result of the imagination(requireswork,too,ofcourse).Somemaynotbelieveit,butIspent hoursperfectingwhateverIdid. Ones moral virtue is reflected in ones work. - The moral worth of a man influenceswhathisjobshouldbe.Oncehefunctionsthewayheoughtto,heis happy. Attaininghappinessinwork.-Inorderthatpeoplemaybehappyintheirwork thesethreethingsareneeded: Theymustbeforit. Theymustnotdotoomuchofit. Theymusthaveasenseofsuccessinit. Neverprostituteyourprinciplesinyourwork.-Iwillneverprostitutemyselfin anywaythatIdowhatIdon'tbelievein. Ontheneedtoholdsomethinginreserve.-Don'tenterintoanythingwitha totalityofspirit.Somethingmustbeheldback.TheOccidentalhomilyisDont\",\n",
       "  'answer': 'Focus on working hard and using your imagination to perfect your craft. Let your moral virtue guide your choices in work. Find joy in what you do by being passionate, not overdoing it, and feeling successful. Stay true to your beliefs and never compromise your principles in your work. Remember to hold something back and not give your all to everything you do.',\n",
       "  'question_groundedness_score': 5,\n",
       "  'question_groundedness_score_rationale': 'The context provides a clear answer to the question of how to attain happiness in work. It outlines three specific conditions needed for happiness in work: being for it, not doing too much of it, and having a sense of success in it. These points directly address the question and offer a comprehensive response based on the given context.\\n\\n'},\n",
       " {'question': 'How can I balance investing myself in learning as an actor while not putting all my eggs in one basket?',\n",
       "  'context': \"totalityofspirit.Somethingmustbeheldback.TheOccidentalhomilyisDont putallyoureggsinonebasketbutitisspokenofmaterialthings.Irefertothe emotional,intellectual,spiritual.IcanillustratemybeliefsbywhatIpracticein my own life. I have a lot to learn as an actor. I am learning. I am investing muchofmyselfinit,butnotall. Onofficework.IneverwantedajobinanofficeoranyjobthatIhadtowork eighthoursadayat-dayinanddayout.Idon'tthinkIcouldhavestoodit.I'm\",\n",
       "  'answer': \"Balance investing in learning as an actor while not putting all your eggs in one basket by dedicating yourself to learning and growing in your craft, while also exploring other interests and opportunities. Keep a diverse range of experiences and skills to fall back on, so that you are not solely reliant on one path. Remember to nurture your emotional, intellectual, and spiritual well-being alongside your acting pursuits. It's important to invest in yourself as an actor, but also important to have a well-rounded approach to your life and career.\",\n",
       "  'question_groundedness_score': 3,\n",
       "  'question_groundedness_score_rationale': \"The context provides a perspective on not investing oneself entirely in one area, using the metaphor of not putting all eggs in one basket. It mentions the speaker's approach to learning as an actor and their avoidance of monotonous office work. However, it does not provide specific strategies or advice on how to balance investing in acting with other pursuits. The context is somewhat relevant but lacks detailed guidance for the question.\\n\\n\"},\n",
       " {'question': 'How can I respond to the totality with a partial, fragmentary pattern?',\n",
       "  'context': 'Totality Do not cling to partiality. -Do not cling to partiality, however fantastic - see thingsfromTOTALITY. Beaffectedbythetotalityofcreativeenergy.-Move\"playfullyserious\"fromthe creativetide(primordialcreativeenergy)affectedbyittotallyandnotamere fragment. Totalityandenlightenment.-Toobtainenlightenmentmeanstheextinctionof everything which obscures the \"true knowledge,\" the \"real life;\" at the same time,itimplies\"boundlessexpansion,\"and,indeedemphasisshouldfallnoton thecultivationofthe\"particulardepartmentwhichmergesintothetotality,\"but ratheron\"thetotalitythatentersandunitesthatparticulardepartment!\" Thereisnoeffectivesegmentofatotality.-Thereisnosuchthingasaneffective segment of a totality. How can one respond to the totality with [a] partial, fragmentarypattern?Inthegreaterthelesseris,butinthelesserthegreateris not. The way to freedom is through',\n",
       "  'answer': 'Respond to the totality with a partial, fragmentary pattern by not clinging to partiality. See things from totality and be affected by the totality of creative energy. Move playfully serious from the creative tide affected by it totally and not a mere fragment. Obtain enlightenment by extinguishing everything that obscures true knowledge and real life, emphasizing the totality that enters and unites the particular department. There is no effective segment of a totality. In the greater, the lesser is, but in the lesser, the greater is not. The way to freedom is through.',\n",
       "  'question_groundedness_score': 5,\n",
       "  'question_groundedness_score_rationale': 'The context provided emphasizes the idea that one should not respond to totality with a partial or fragmentary pattern. It suggests that totality cannot be effectively addressed through partiality, implying that a partial, fragmentary pattern is inadequate for responding to totality. The question directly asks how one can respond to totality with a partial pattern, which the context suggests is not possible or effective. Therefore, the context provides a clear answer to the question by indicating that such a response is not feasible.\\n\\n'},\n",
       " {'question': 'How can I achieve ultimate freedom through self-knowledge and totality?',\n",
       "  'context': 'partial, fragmentarypattern?Inthegreaterthelesseris,butinthelesserthegreateris not. The way to freedom is through totality. -Fluidity leads to interchangeability. Self-knowledgeleadstoawareness.Totalityleadstoultimatefreedom. Beyondlikinganddisliking.-Youwillthenseeitwithoutlikeordislike,you simplysee,andinthisseeing,thewholeispresentedandnotthepartial.',\n",
       "  'answer': 'Achieve ultimate freedom through self-knowledge and totality by understanding that in the greater, the lesser is, but in the lesser, the greater is not. Embrace fluidity and interchangeability. Seek self-knowledge to gain awareness and strive for totality to reach ultimate freedom. Move beyond liking and disliking, and simply see without bias. In this seeing, the whole is presented, not the partial.',\n",
       "  'question_groundedness_score': 2,\n",
       "  'question_groundedness_score_rationale': 'The context provides philosophical statements about self-knowledge, awareness, and totality leading to ultimate freedom. However, it lacks specific, practical steps or detailed explanations on how to achieve ultimate freedom through these concepts. The context is abstract and does not directly answer the question with clear guidance or actionable advice.\\n\\n'},\n",
       " {'question': 'How can I strengthen my mind and properly examine my state during times of adversity?',\n",
       "  'context': \"Adversity Adversityisbeneficialtous.-Prosperityisapttopreventusfromexaminingour conduct;butadversityleadsustothinkproperlyofourstate,andsoisbeneficial tous. Adversitycausesthemindtothinkproperly.-Inatimewheneverythinggoes well,mymindispamperedwithenjoyment,possessiveness,etc.Onlyintimes ofadversity,privation,ormishap,doesmymindfunctionandthinkproperlyof mystate.Thiscloseexaminationofselfstrengthensmymindandleadsmeto understandandbeunderstood. The value of foolish questions. - A wise man can learn more from a foolish questionthanafoolcanlearnfromawiseanswer. Never waste energy on worries and negative thoughts. - I mean who has the mostinsecurejobasIhave?WhatdoIliveon?MyfaithinmyabilitythatI'll makeit.Suremybackscrewedmeupgoodforayearbutwitheveryadversity\",\n",
       "  'answer': \"To strengthen your mind and properly examine your state during times of adversity, you must embrace the benefits of adversity, allow your mind to think properly, and value self-examination. Remember that a wise man can learn from foolish questions, so don't waste energy on worries and negative thoughts. Trust in your ability to overcome challenges and have faith in yourself.\",\n",
       "  'question_groundedness_score': 5,\n",
       "  'question_groundedness_score_rationale': \"The context discusses the benefits of adversity in prompting self-examination and strengthening the mind. It suggests that adversity causes the mind to think properly and leads to a close examination of oneself, which strengthens the mind. This directly relates to the question about strengthening the mind and examining one's state during adversity. Therefore, the context provides a clear basis for answering the question.\\n\\n\"},\n",
       " {'question': 'How can I turn anxiety into a defense mechanism?',\n",
       "  'context': 'makeit.Suremybackscrewedmeupgoodforayearbutwitheveryadversity comesablessingbecauseashockactsasaremindertooneselfthatwemustnot getstaleinroutine. Anxieryisadefense.-Don\\'tbeforecastingevilunlessitiswhatyoucanguard against.Anxietyisgoodfornothingifwecan\\'tturnitintoadefense. Thereisnoshameinlosing.-Itisnotashametobeknockeddownbyother people.Theimportantthingistoaskwhenyou\\'rebeingknockeddown,\"Why amIbeingknockeddown?\"Ifapersoncanreflectinthisway,thenthereishope',\n",
       "  'answer': \"Turn anxiety into a defense mechanism by using it as a reminder to not get stale in routine. Don't fear what you can guard against. Reflect on why you're being knocked down and there is hope in that.\",\n",
       "  'question_groundedness_score': 3,\n",
       "  'question_groundedness_score_rationale': 'The context provides a perspective on anxiety, suggesting that it can be turned into a defense mechanism by using it as a reminder or a prompt to guard against potential issues. However, it does not provide specific steps or detailed guidance on how to achieve this transformation. The context is somewhat relevant but lacks clarity and depth in addressing the question directly.\\n\\n'},\n",
       " {'question': 'How can I prevent my beliefs from becoming rigid and isolating like those of established organizations?',\n",
       "  'context': 'knowledge,apreservedcure-allformassconditioning.Insodoing,thefollowers have made this knowledge not only a holy shrine, but a tomb in which the founder\\'s wisdom is buried. Because of the nature of organisation and preservation,themeanswouldbecomesoelaboratedthattremendousattention mustbegiventothem,andgraduallytheendisforgotten.Thefollowerswill thenacceptthis\"organisedsomething\"asthetotalreality.Ofcourse,manymore \"different\" approaches would spring up, probably as a direct reaction to \"the other\\'s truth.\" Pretty soon these approaches too would become large organisationswitheachclaimingtopossess\"truth\"totheexclusionofallothers. Theproblemsofbelief-Beliefbinds,beliefisolates.Anestablishedsetstyle. Chaineddown.Inbondage.Bound.Itcannevercomprehendthenew,thefresh, theuncreated.Themeansdestroysthefreshness,thenewness,thespontaneous discovery.',\n",
       "  'answer': 'Prevent your beliefs from becoming rigid and isolating by avoiding the trap of organized preservation. Do not let your beliefs become a tomb where wisdom is buried. Stay open to new ideas and avoid getting chained down by established ways of thinking. Embrace freshness, newness, and spontaneous discovery.',\n",
       "  'question_groundedness_score': 3,\n",
       "  'question_groundedness_score_rationale': 'The context discusses the nature of belief systems and how they can become rigid and isolating when they are organized and preserved in a way that focuses more on the means than the end. It suggests that belief systems can become like tombs where original wisdom is buried, and that they can lead to isolation and bondage. The context implies that to prevent beliefs from becoming rigid, one should avoid over-organizing and preserving them in a way that loses sight of their original purpose. However, the context does not provide specific strategies or steps for preventing beliefs from becoming rigid, so the answer is somewhat implicit rather than explicit.\\n\\n'},\n",
       " {'question': 'How can I break free from the patterns that are blocking my real feelings and spontaneous discoveries?',\n",
       "  'context': 'theuncreated.Themeansdestroysthefreshness,thenewness,thespontaneous discovery. Methodsblockrealfeelings.-Whenrealfeelingoccurs,likeanger,fear,etc., canone\"express\"himselfwiththeclassicalmethod,orishemerelylisteningto hisownscreamsandyellsandmechanicallyperforminghisroutine? Slaves to pattern. - Because one does not want to be disturbed, to be made uncertain, he establishes a pattern of conduct, of thought, a pattern of relationshiptoman,etc.Thenhebecomesaslavetothepatternandtakesthe patterntobetherealthing. Methods place obstacles in the way of knowledge.- By an error repeated throughouttheages,truth,becomingalaworafaith,placesobstaclesintheway of knowledge. Method, which is in its very substance ignorance, encloses it withinaviciouscircle.Weshouldbreaksuchcirclesnotbyseekingknowledge, butbydiscoveringthecauseofignorance.',\n",
       "  'answer': 'Break free from patterns blocking real feelings and spontaneous discoveries by questioning established methods, recognizing when you are just going through the motions, and being willing to embrace uncertainty and discomfort. Challenge the patterns you have created, break free from the cycle of ignorance, and seek the root cause of your limitations. Only then can you truly experience genuine emotions and make spontaneous discoveries.',\n",
       "  'question_groundedness_score': 3,\n",
       "  'question_groundedness_score_rationale': 'The context discusses the negative impact of methods and patterns on real feelings and spontaneous discoveries. It suggests that these patterns make one a slave and place obstacles in the way of knowledge. The context implies that breaking free involves discovering the cause of ignorance rather than seeking knowledge. However, it does not provide specific steps or detailed guidance on how to break free from these patterns. Therefore, while the context offers a philosophical perspective, it lacks concrete advice or actionable steps.\\n\\n'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "rag_eval_set = Dataset.from_list(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You need to provide a `token` or be logged in to Hugging Face with `huggingface-cli login`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrag_eval_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mharpreetsahota/LI_Learning_RAG_Eval_Set\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/lil_llama_index/lib/python3.10/site-packages/datasets/arrow_dataset.py:5422\u001b[0m, in \u001b[0;36mDataset.push_to_hub\u001b[0;34m(self, repo_id, config_name, split, private, token, branch, max_shard_size, num_shards, embed_external_files)\u001b[0m\n\u001b[1;32m   5417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   5418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to push_to_hub: please specify either max_shard_size or num_shards, but not both.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5419\u001b[0m     )\n\u001b[1;32m   5420\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m config_name \u001b[38;5;28;01mif\u001b[39;00m config_name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[0;32m-> 5422\u001b[0m repo_id, split, uploaded_size, dataset_nbytes, repo_files, deleted_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_push_parquet_shards_to_hub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5425\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbranch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbranch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_shard_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5431\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_external_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_external_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5432\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5433\u001b[0m organization, dataset_name \u001b[38;5;241m=\u001b[39m repo_id\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5434\u001b[0m info_to_dump \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/opt/conda/envs/lil_llama_index/lib/python3.10/site-packages/datasets/arrow_dataset.py:5218\u001b[0m, in \u001b[0;36mDataset._push_parquet_shards_to_hub\u001b[0;34m(self, repo_id, data_dir, split, private, token, branch, max_shard_size, num_shards, embed_external_files)\u001b[0m\n\u001b[1;32m   5215\u001b[0m token \u001b[38;5;241m=\u001b[39m token \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m HfFolder\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[1;32m   5217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 5218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   5219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to provide a `token` or be logged in to Hugging Face with `huggingface-cli login`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5220\u001b[0m     )\n\u001b[1;32m   5222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5223\u001b[0m     split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mOSError\u001b[0m: You need to provide a `token` or be logged in to Hugging Face with `huggingface-cli login`."
     ]
    }
   ],
   "source": [
    "rag_eval_set.push_to_hub(\"harpreetsahota/LI_Learning_RAG_Eval_Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can find the dataset on Hugging Face\n",
    "\n",
    "You don't have to run the examples here if you don't want to incur costs from OpenAI. \n",
    "\n",
    "[Here's the dataset](https://huggingface.co/datasets/harpreetsahota/LI_Learning_RAG_Eval_Set). You can click around and explore using the dataset viewer. If you sign-up for an account on Hugging Face, feel free to [follow me](https://huggingface.co/harpreetsahota)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1af0f326bee415a993ed22dd61209bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/466 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9d14d155424739abfc319d85d01e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 295k/295k [00:00<00:00, 785kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe7bae766e8463a8e0429cbcb79b1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea3a61083944696ac4e430ceb53d172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/316 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Loading a dataset cached in a LocalFileSystem is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m----> 3\u001b[0m rag_eval_set \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mharpreetsahota/LI_Learning_RAG_Eval_Set\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/lil_llama_index/lib/python3.10/site-packages/datasets/load.py:2166\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2163\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2164\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   2165\u001b[0m )\n\u001b[0;32m-> 2166\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2167\u001b[0m \u001b[38;5;66;03m# Rename and cast features to match task schema\u001b[39;00m\n\u001b[1;32m   2168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2169\u001b[0m     \u001b[38;5;66;03m# To avoid issuing the same warning twice\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/lil_llama_index/lib/python3.10/site-packages/datasets/builder.py:1173\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[1;32m   1171\u001b[0m is_local \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m is_remote_filesystem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local:\n\u001b[0;32m-> 1173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading a dataset cached in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir):\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1176\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: could not find data in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please make sure to call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1177\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilder.download_and_prepare(), or use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1178\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets.load_dataset() before trying to access the Dataset object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1179\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Loading a dataset cached in a LocalFileSystem is not supported."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "rag_eval_set = load_dataset(\"harpreetsahota/LI_Learning_RAG_Eval_Set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lil_llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
