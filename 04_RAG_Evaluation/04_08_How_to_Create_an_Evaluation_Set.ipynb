{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install llama-index==0.10.29 ragas==0.1.7 llama-index-embeddings-openai llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append('../helpers')\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY'] or getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using OpenAI here because Cohere has rate limits for it's free tier. You don't need to run this code yourself if you don't want to incur costs from OpenAI. I'll upload the dataset to the Hugging Face Hub and I'll show you how to download it from there when we need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4-turbo-2024-04-09\", temperature=0.25)\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already cleaned up our data before. Recall that we've persisted the `Document` objects to disk using a Docstore in such a way that each Document object represents cleaned text from a page of a book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_documents_from_docstore\n",
    "\n",
    "documents = get_documents_from_docstore(\"../data/words-of-the-senpais\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a set of `Documents` for the evaluation set\n",
    "\n",
    "- üìö **`group_documents_by_author`**: A utility function that sorts a collection of douments into groups based on who wrote them.\n",
    "\n",
    "- üóÇÔ∏è **How It Works**: It creates a  dictionary where each author's name is linked to all the documents they've written.\n",
    "  - Starts with an empty dictionary ready to be filled with author-document pairs.\n",
    "  - Goes through each document, checking the author's name and adding the document under the appropriate author in the dictionary.\n",
    "  - If a document doesn't list an author, it skips adding that document with a warning note.\n",
    "\n",
    "- üìù **Input**: Takes a list of `Document` objects, each with metadata that includes the `author` field (the name of its author).\n",
    "\n",
    "- üîñ **Output**: Outputs a dictionary that groups all the documents by their respective authors.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from utils import group_documents_by_author\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "documents_by_author = group_documents_by_author(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- üìö **`sample_documents`**: Picks a set number of documents randomly from each author's collection within a grouped dictionary.\n",
    "\n",
    "- üé≤ **Sampling Logic**: It tries to get a specific number of documents for each author. If an author doesn't have enough documents, it alerts you.\n",
    "  - Begins with an empty list for storing selected samples.\n",
    "  - Loops through each author, considers only docs with >500 characters, checking if there are enough documents to fulfill the sampling requirement.\n",
    "  - Randomly selects the desired number of documents from those available, adding them to the overall sample list.\n",
    "  - Issues a warning if the documents under an author are too few to meet the sampling number.\n",
    "\n",
    "- üìù **Input**: Receives a dictionary where authors are keys and values are lists of their documents, along with an optional number of documents to sample per author.\n",
    "\n",
    "- üîñ **Output**: Outputs a list of randomly chosen documents from across all authors, sticking to the specified number per author when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sample_documents\n",
    "\n",
    "docs_for_eval_set = sample_documents(documents_by_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_metadata_keys = ['file_name', 'page_number']\n",
    "\n",
    "for doc in docs_for_eval_set:\n",
    "    doc.excluded_llm_metadata_keys = exclude_metadata_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author 'Naval Ravikant' has 10 documents.\n",
      "Author 'Balaji Srinivasan' has 10 documents.\n",
      "Author 'Paul Graham' has 10 documents.\n",
      "Author 'Nassim Nicholas Taleb' has 10 documents.\n",
      "Author 'Seneca' has 10 documents.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_documents_by_author(documents):\n",
    "    \"\"\"\n",
    "    Count the number of documents each author has in a list of document objects.\n",
    "\n",
    "    :param documents: List of document objects with metadata containing 'author'.\n",
    "    :return: A Counter object with authors as keys and counts of their documents as values.\n",
    "    \"\"\"\n",
    "    # Extract the author from each document's metadata and count occurrences\n",
    "    author_counts = Counter(doc.metadata['author'] for doc in documents if 'author' in doc.metadata)\n",
    "    return author_counts\n",
    "\n",
    "author_counts = count_documents_by_author(docs_for_eval_set)\n",
    "for author, count in author_counts.items():\n",
    "    print(f\"Author '{author}' has {count} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use an in-memory vector database to create an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import setup_vector_store, create_index\n",
    "\n",
    "vector_store = setup_vector_store(qdrant_url=\":memory:\", qdrant_api_key=None, collection_name=\"test-set-generation\")\n",
    "\n",
    "index = create_index(vector_store=vector_store, documents=docs_for_eval_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex has a built in dataset generator\n",
    "\n",
    "The `RagDatasetGenerator` automatically generates a dataset for RAG evaluation. \n",
    "\n",
    "This dataset is created based on a set of documents to query. The generated dataset will have diverse set of queries and their corresponding responses, which we'll use to evaluate the performance various RAG strategies.\n",
    "\n",
    "You can look at the [source code](https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/llama_dataset/generator.py) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question generation prompt\n",
    "\n",
    "If you look at the source code, you'll see that the RagDatsetGenerator takes an optional string argument called `question_gen_query`. This string os used to generate questions from the document context. It instructs the model to act as a teacher/professor and create diverse questions based on the provided context. The default value for this is:\n",
    "\n",
    "```text\n",
    "You are a Teacher/Professor. Your task is to setup 2 questions for an upcoming quiz/examination. The questions should be diverse in nature across the document. Restrict the questions to the context information provided.\n",
    "```\n",
    "\n",
    "You can verify this by running:\n",
    "\n",
    "```python\n",
    "print(dataset_generator.question_gen_query)\n",
    "```\n",
    "\n",
    "These is a good starting point for building an evaluation dataset, but we can be more specific for our use case. The usecase I have in mind is drawing on the wisdom and knowledge of my virtual mentors. I want to come to them questions for advice whenever I need it, so we should create an evaluation dataset from that perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a high-performer seeking wisdom and advice. You've aggregated the writings of these influential thinkers:\n",
      "\n",
      "- Naval Ravikant: Known for his insights on how to build wealth and achieve happiness through developing specific knowledge, embracing accountability, playing long-term games, and understanding the power of compound interest in all areas of life.\n",
      "\n",
      "- Balaji Srinivasan: Has insights on how to think independently, identify opportunities, and build a better future through the strategic application of technology and clear reasoning.\n",
      "\n",
      "- Paul Graham: Provides advice on the hacker mindset, arguing that hackers are really makers and creators - akin to painters - who can leverage their unique way of thinking to push boundaries, challenge the status quo, and shape the future through technology and entrepreneurship.\n",
      "\n",
      "- Nassim Nicholas Taleb: Argues for \"Skin in the Game\", that is having a personal stake in the outcome is necessary for fairness as it aligns incentives and exposes individuals to both the potential rewards and risks of their decisions.\n",
      "\n",
      "- Seneca: Offers timeless advice on how to cultivate wisdom, build mental resilience, and live a life of purpose and contentment by focusing on what is essential, mastering one's emotions, and aligning oneself with nature.\n",
      "\n",
      "Your task is to ask {num_questions_per_chunk} questions, from the first-person perspective, seeking actionable advice or practical tips that you can apply in your own life.\n",
      "\n",
      "Restrict the questions to the context information provided, ask the questions from the first-person perspective. There is no need to address the thinker directly, they know you're speaking to them specifically.\n",
      "\n",
      "Ask the question directly and as succinctly as possible.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from prompts import QUESTION_GEN_QUERY\n",
    "\n",
    "print(QUESTION_GEN_QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are also a couple of other prompts that are used to generate an evaluation dataset.\n",
    "\n",
    "The `text_question_template` and `text_qa_template` are prompt templates to generate questions and question-answer pairs, respectively. If not provided, default templates are used:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " **Prompt Key**: text_question_template\n",
       "**Text:**\n",
       "```\n",
       "Context information is below.\n",
       "---------------------\n",
       "{context_str}\n",
       "---------------------\n",
       "Given the context information and not prior knowledge.\n",
       "generate only questions based on the below query.\n",
       "{query_str}\n",
       "\n",
       "```\n",
       "\n",
       "**Prompt Key**: text_qa_template\n",
       "**Text:**\n",
       "```\n",
       "Context information is below.\n",
       "---------------------\n",
       "{context_str}\n",
       "---------------------\n",
       "Given the context information and not prior knowledge, answer the query.\n",
       "Query: {query_str}\n",
       "Answer: \n",
       "```\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import display_prompt_dict\n",
    "display_prompt_dict(RagDatasetGenerator(None).get_prompts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's implement some custom prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're seeking advice on navigating complex decisions, building wealth and happiness, identifying opportunities, embracing innovation, and living a meaningful life from one of the following influential thinkers:\n",
      "\n",
      "- Naval Ravikant: Known for his insights on how to build wealth and achieve happiness through developing specific knowledge, embracing accountability, playing long-term games, and understanding the power of compound interest in all areas of life.\n",
      "\n",
      "- Balaji Srinivasan: Has insights on how to think independently, identify opportunities, and build a better future through the strategic application of technology and clear reasoning.\n",
      "\n",
      "- Paul Graham: Provides advice on the hacker mindset, arguing that hackers are really makers and creators - akin to painters - who can leverage their unique way of thinking to push boundaries, challenge the status quo, and shape the future through technology and entrepreneurship.\n",
      "\n",
      "- Nassim Nicholas Taleb: Argues for \"Skin in the Game\", that is having a personal stake in the outcome is necessary for fairness as it aligns incentives and exposes individuals to both the potential rewards and risks of their decisions.\n",
      "\n",
      "- Seneca: Offers timeless advice on how to cultivate wisdom, build mental resilience, and live a life of purpose and contentment by focusing on what is essential, mastering one's emotions, and aligning oneself with nature.\n",
      "\n",
      "Context information is below, incuding:\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "\n",
      "Given the context information and the identity of the thinker that authored it, generate questions that seek actionable advice or practical tips that you can apply in your own life. \n",
      "\n",
      "Restrict the questions to the context information provided and ask the questions from the first-person perspective. \n",
      "\n",
      "There is no need to address the thinker directly, they know you're speaking to them specifically. Ask the question directly and as succinctly as possible.\n",
      "\n",
      "{query_str}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.prompts.base import PromptTemplate\n",
    "from prompts import TEXT_QUESTION_STR\n",
    "\n",
    "text_question_template = PromptTemplate(TEXT_QUESTION_STR)\n",
    "\n",
    "print(text_question_template.get_template())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're provided with context, which is the writing from of the following influential thinkers:\n",
      "\n",
      "- Naval Ravikant: Naval would advise you to focus on building unique knowledge, taking ownership of your actions, playing long-term games with compounding in mind, and aligning your pursuits with genuine passion.\n",
      "\n",
      "- Balaji Srinivasan: Balaji would encourage you to think critically and independently, leverage technology strategically, and develop a clear vision for the change you want to see.\n",
      "\n",
      "- Paul Graham: Paul would suggest embracing the hacker mindset ‚Äì a way of thinking that values problem-solving, building, and continuous learning to push boundaries and challenge conventions.\n",
      "\n",
      "- Nassim Nicholas Taleb: Nassim would emphasize the importance of having \"skin in the game,\" ensuring your incentives align with the outcomes and you are exposed to both the rewards and consequences of your choices.\n",
      "\n",
      "- Seneca: Seneca would advise focusing on essential things, mastering your emotions through Stoic principles, and living in accordance with nature and reason.\n",
      "\n",
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "\n",
      "Given the context information and information about who authored it, answer the query. \n",
      "\n",
      "When providing advice, speak directly to the asker and use the \"you\" voice (second-person perspective). There is no need to identify yourself in your response, the asker knows who you are. \n",
      "\n",
      "Query: {query_str}\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from prompts import TEXT_QA_STRING\n",
    "\n",
    "text_qa_template = PromptTemplate(TEXT_QA_STRING)\n",
    "\n",
    "print(text_qa_template.get_template())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "dataset_generator= RagDatasetGenerator(\n",
    "    nodes=docs_for_eval_set,\n",
    "    metadata_mode = MetadataMode.LLM,\n",
    "    workers=os.cpu_count(),\n",
    "    num_questions_per_chunk=2,\n",
    "    show_progress=True,\n",
    "    llm=llm,\n",
    "    text_question_template=text_question_template,\n",
    "    text_qa_template=text_qa_template,\n",
    "    question_gen_query=QUESTION_GEN_QUERY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " **Prompt Key**: text_question_template\n",
       "**Text:**\n",
       "```\n",
       "You're seeking advice on navigating complex decisions, building wealth and happiness, identifying opportunities, embracing innovation, and living a meaningful life from one of the following influential thinkers:\n",
       "\n",
       "- Naval Ravikant: Known for his insights on how to build wealth and achieve happiness through developing specific knowledge, embracing accountability, playing long-term games, and understanding the power of compound interest in all areas of life.\n",
       "\n",
       "- Balaji Srinivasan: Has insights on how to think independently, identify opportunities, and build a better future through the strategic application of technology and clear reasoning.\n",
       "\n",
       "- Paul Graham: Provides advice on the hacker mindset, arguing that hackers are really makers and creators - akin to painters - who can leverage their unique way of thinking to push boundaries, challenge the status quo, and shape the future through technology and entrepreneurship.\n",
       "\n",
       "- Nassim Nicholas Taleb: Argues for \"Skin in the Game\", that is having a personal stake in the outcome is necessary for fairness as it aligns incentives and exposes individuals to both the potential rewards and risks of their decisions.\n",
       "\n",
       "- Seneca: Offers timeless advice on how to cultivate wisdom, build mental resilience, and live a life of purpose and contentment by focusing on what is essential, mastering one's emotions, and aligning oneself with nature.\n",
       "\n",
       "Context information is below, incuding:\n",
       "---------------------\n",
       "{context_str}\n",
       "---------------------\n",
       "\n",
       "Given the context information and the identity of the thinker that authored it, generate questions that seek actionable advice or practical tips that you can apply in your own life. \n",
       "\n",
       "Restrict the questions to the context information provided and ask the questions from the first-person perspective. \n",
       "\n",
       "There is no need to address the thinker directly, they know you're speaking to them specifically. Ask the question directly and as succinctly as possible.\n",
       "\n",
       "{query_str}\n",
       "\n",
       "```\n",
       "\n",
       "**Prompt Key**: text_qa_template\n",
       "**Text:**\n",
       "```\n",
       "You're provided with context, which is the writing from of the following influential thinkers:\n",
       "\n",
       "- Naval Ravikant: Naval would advise you to focus on building unique knowledge, taking ownership of your actions, playing long-term games with compounding in mind, and aligning your pursuits with genuine passion.\n",
       "\n",
       "- Balaji Srinivasan: Balaji would encourage you to think critically and independently, leverage technology strategically, and develop a clear vision for the change you want to see.\n",
       "\n",
       "- Paul Graham: Paul would suggest embracing the hacker mindset ‚Äì a way of thinking that values problem-solving, building, and continuous learning to push boundaries and challenge conventions.\n",
       "\n",
       "- Nassim Nicholas Taleb: Nassim would emphasize the importance of having \"skin in the game,\" ensuring your incentives align with the outcomes and you are exposed to both the rewards and consequences of your choices.\n",
       "\n",
       "- Seneca: Seneca would advise focusing on essential things, mastering your emotions through Stoic principles, and living in accordance with nature and reason.\n",
       "\n",
       "Context information is below.\n",
       "---------------------\n",
       "{context_str}\n",
       "---------------------\n",
       "\n",
       "Given the context information and information about who authored it, answer the query. \n",
       "\n",
       "When providing advice, speak directly to the asker and use the \"you\" voice (second-person perspective). There is no need to identify yourself in your response, the asker knows who you are. \n",
       "\n",
       "Query: {query_str}\n",
       "Answer:\n",
       "\n",
       "```\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_prompt_dict(dataset_generator.get_prompts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Note:** This took ~17 minutes to run and cost ~7$ USD in OpenAI calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "rag_dataset = dataset_generator.generate_dataset_from_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset.save_json(\"rag_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# generator with openai models\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(     \n",
    "    generator_llm=generator_llm,\n",
    "    critic_llm=critic_llm,\n",
    "    embeddings=embeddings,\n",
    ")\n",
    "\n",
    "distributions = {\n",
    "    simple: 0.3,\n",
    "    multi_context: 0.5,\n",
    "    reasoning: 0.2\n",
    "}\n",
    "\n",
    "generator_llamaindex = generator.generate_with_llamaindex_docs(\n",
    "    documents = docs_for_eval_set,\n",
    "    distributions=distributions,\n",
    "    test_size=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_llamaindex.to_dataset()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lil_llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
