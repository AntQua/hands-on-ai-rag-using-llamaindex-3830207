{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install llama-index==0.10.37 llama-index-embeddings-cohere--0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO_API_KEY = os.environ['CO_API_KEY'] or getpass(\"Enter your Cohere API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üóÇÔ∏è Indexing\n",
    "\n",
    "An `Index` is a data structure that allows for the quick retrieval of relevant context for a user query. \n",
    "\n",
    "It is the core foundation for retrieval-augmented generation (RAG) use-cases. Indexes are built from `Documents` and are used to build Retrievers, Query Engines and Chat Engines. All of which enable question & answer and chat over your data.\n",
    "\n",
    "- üìÇ After loading your data, you're ready to construct an `Index`.\n",
    "\n",
    "- üåê **Vector Store Index:** The most common Index type. It segments your `Documents` into `Nodes` and generates vector embeddings for each node's text, prepping them for LLM queries.\n",
    "\n",
    "- üîÑ **Vector Store Index Process:** Parse raw texts into document objects, split document objects into chunks/nodes, then convert all your nodes into embeddings and store them in a vector database.\n",
    "\n",
    "### ‚öôÔ∏è Embedding Text\n",
    "\n",
    "First, let's see what an embedding is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "\n",
    "embed_v3 = CohereEmbedding(model_name=\"embed-english-v3.0\")\n",
    "\n",
    "embed_v3_light = CohereEmbedding(model_name=\"embed-english-light-v3.0\")\n",
    "\n",
    "embed_v2 = CohereEmbedding(model_name=\"embed-english-v2.0\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also use local embedding models, by using an embedding model from Hugging Face. Check the [MTEB Leaderboard for what's hot](huggingface.co/spaces/mteb/leaderboard)\n",
    "\n",
    "```python\n",
    "\n",
    "pip install llama-index-embeddings-huggingface\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "hf_embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "```\n",
    "\n",
    "#### If you're running locally and on a CPU, though, you may want to use `FastEmbed`. These models are lightweight, quantized, and optimized for CPU. Here are the [supported models](https://qdrant.github.io/fastembed/examples/Supported_Models/)\n",
    "\n",
    "This is how you can instantiate a `FastEmbed` model:\n",
    "\n",
    "```python\n",
    "pip install llama-index-embeddings-fastembed\n",
    "\n",
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "\n",
    "embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-large-en-v1.5-quantized\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"A\"\n",
    "\n",
    "string_2 = \"This is a complete sentence.\"\n",
    "\n",
    "string_3 = \"\"\"In the pursuit of a life well-lived, one must recognize the transient nature of the \n",
    "material world and the enduring value of virtue. The Sikh Gurus taught us that the Divine Light \n",
    "resides within all, and thus, we are united in our essence beyond the superficial distinctions of \n",
    "caste, creed, or status. Similarly, the Stoics emphasized the cultivation of inner virtues such as courage, \n",
    "temperance, and wisdom, understanding that true freedom lies in mastery over one's own perceptions and actions. \n",
    "As we navigate the vicissitudes of life, let us remember that our choices are our own, and in choosing virtue, \n",
    "we align ourselves with the cosmic order and the teachings of the Gurus. It is through selfless service, \n",
    "compassion, and the relentless pursuit of truth that we may attain a state of inner peace and contribute \n",
    "to the harmony of the world, embodying the principles of both Sikhism and Stoicism in our daily lives\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_embedding = embed_v3.get_text_embedding(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_dimensions(embed_model, list_of_strings):\n",
    "    embeddings = embed_model.get_text_embedding_batch(list_of_strings)   \n",
    "    embed_lens = []\n",
    "    for embedding in embeddings:\n",
    "        embed_lens.append(len(embedding))\n",
    "    return embed_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1024, 1024, 1024]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embedding_dimensions(embed_v3, [string, string_2, string_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[384, 384, 384]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embedding_dimensions(embed_v3_light, [string, string_2, string_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4096, 4096, 4096]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embedding_dimensions(embed_v2, [string, string_2, string_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18940321498701687"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_v3.similarity(\n",
    "    embed_v3.get_text_embedding(\"\"\"In embracing both the wisdom of the Sikh Gurus and the Stoic philosophers, \n",
    "                              we find a path to tranquility by accepting what is beyond our control and focusing \n",
    "                              our efforts on living virtuously and with purpose.\"\"\"), \n",
    "    embed_v3.get_text_embedding(string_2),\n",
    "    mode=\"cosine\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Index\n",
    "\n",
    "First, let's get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def load_text_from_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches and returns the text content from the specified URL.\n",
    "\n",
    "    Parameters:\n",
    "    - url: The URL of the text file to fetch.\n",
    "\n",
    "    Returns:\n",
    "    - The text content of the file if the request is successful; otherwise, an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # This will raise an HTTPError if the response was an error\n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        return f\"Failed to load content from {url}. Error: {e}\"\n",
    "\n",
    "url = \"https://www.gutenberg.org/files/10763/10763-0.txt\"\n",
    "\n",
    "text_content = load_text_from_url(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚è≥ Generating embeddings can be time-consuming, especially with large volumes of text, due to numerous API calls required. \n",
    "\n",
    "Now, create an index by passing a **list of Documents**. To save time, and cost, we will only use 10,000 characters of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document, VectorStoreIndex\n",
    "\n",
    "full_document = Document(text=text_content)\n",
    "\n",
    "partial_document = Document(text=text_content[50000:60000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agut. \"What\\'s that?\" \"You didn\\'t think you could do it.\"\\r\\nSo the man who thinks he can\\'t pass a lion, can\\'t. But the man who\\r\\nthinks he can, can. Indeed he oftentimes finds that the lion isn\\'t\\r\\nreally there at all.\\r\\n\\r\\n\\r\\n  I dare not!--\\r\\n               Look! the road is very dark--\\r\\n  The trees stir softly and the bushes shake,\\r\\n  The long grass rustles, and the darkness moves\\r\\n  Here! there! beyond--!\\r\\n  There\\'s something crept across the road just now!\\r\\n  And you would have me go--?\\r\\n  Go _there_, through that live darkness, hideous\\r\\n  With stir of crouching forms that wait to kill?\\r\\n  Ah, _look_! See there! and there! and there again!\\r\\n  Great yellow, glassy eyes, close to the ground!\\r\\n  Look! Now the clouds are lighter I can see\\r\\n  The long slow lashing of the sinewy tails,\\r\\n  And the set quiver of strong jaws that wait--!\\r\\n  Go there? Not I! Who dares to go who sees\\r\\n  So perfectly the lions in the path?\\r\\n\\r\\n  Comes one who dares.\\r\\n                       Afraid at first, yet bound\\r\\n  On such high errand as no fear could stay.\\r\\n  Forth goes he, with lions in his path.\\r\\n  And then--?\\r\\n              He dared a death of agony--\\r\\n  Outnumbered battle with the king of beasts--\\r\\n  Long struggles in the horror of the night--\\r\\n  Dared, and went forth to meet--O ye who fear!\\r\\n  Finding an empty road, and nothing there--\\r\\n  And fences, and the dusty roadside trees--\\r\\n  Some spitting kittens, maybe, in the grass.\\r\\n\\r\\n\\r\\n_Charlotte Perkins Gilman._\\r\\n\\r\\nFrom \"In This Our World.\"\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nTHE ANSWER\\r\\n\\r\\n\\r\\nBob Fitzsimmons lacked the physical bulk of the men he fought, was\\r\\nungainly in build and movement, and not infrequently got himself floored\\r\\nin the early rounds of his contests. But many people consider him the\\r\\nbest fighter for his weight who ever stepped into the prize ring. Not a\\r\\nfavorite at first, he won the popular heart by making good. Of course he\\r\\nhad great natural powers; from any position when the chance at last came\\r\\nhe could dart forth a sudden, wicked blow that no human being could\\r\\nwithstand. But more formidable still was the spirit which gave him cool\\r\\nand complete command of all his resources, and made him most dangerous\\r\\nwhen he was on the verge of being knocked out.\\r\\n\\r\\n\\r\\n  When the battle breaks against you and the crowd forgets to cheer\\r\\n  When the Anvil Chorus echoes with the essence of a jeer;\\r\\n  When the knockers start their panning in the knocker\\'s nimble way\\r\\n  With a rap for all your errors and a josh upon your play--\\r\\n  There is one quick answer ready that will nail them on the wing;\\r\\n  There is one reply forthcoming that will wipe away the sting;\\r\\n  There is one elastic come-back that will hold them, as it should--\\r\\n  Make good.\\r\\n\\r\\n  No matter where you finish in the mix-up or the row,\\r\\n  There are those among the rabble who will pan you anyhow;\\r\\n  But the entry who is sticking and delivering the stuff\\r\\n  Can listen to the yapping as he giggles up his cuff;\\r\\n  The loafer has no come-back and the quitter no reply\\r\\n  When the Anvil Chorus echoes, as it will, against the sky;\\r\\n  But there\\'s one quick answer ready that will wrap them in a hood--\\r\\n  Make good.\\r\\n\\r\\n\\r\\n_Grantland Rice._\\r\\n\\r\\nFrom \"The Sportlight.\"\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nTHE WORLD IS AGAINST ME\\r\\n\\r\\n\\r\\nBabe Ruth doesn\\'t complain that opposing pitchers try to strike him out;\\r\\nhe swings at the ball till he swats it for four bases. Ty Cobb doesn\\'t\\r\\ncomplain that whole teams work wits and muscles overtime to keep him\\r\\nfrom stealing home; he pits himself against them all and comes galloping\\r\\nor hurdling or sliding in. What other men can do any man can do if he\\r\\nworks long enough with a brave enough heart.\\r\\n\\r\\n\\r\\n  \"The world is against me,\" he said with a sigh.\\r\\n  \"Somebody stops every scheme that I try.\\r\\n  The world has me down and it\\'s keeping me there;\\r\\n  I don\\'t get a chance. Oh, the world is unfair!\\r\\n  When a fellow is poor then he can\\'t get a show;\\r\\n  The world is determined to keep him down low.\"\\r\\n\\r\\n  \"What of Abe Lincoln?\" I asked. \"Would you say\\r\\n  That he was much richer than you are to-day?\\r\\n  He hadn\\'t your chance of making his mark,\\r\\n  And his outlook was often exceedingly dark;\\r\\n  Yet he clung to his purpose with courage most grim\\r\\n  And he got to the top. Was the world against him?\\r\\n\\r\\n  \"What of Ben Franklin? I\\'ve oft heard it said\\r\\n  That many a time he went hungry to bed.\\r\\n  He started with nothing but courage to climb,\\r\\n  But patiently struggled and waited his time.\\r\\n  He dangled awhile from real poverty\\'s limb,\\r\\n  Yet he got to the top. Was the world against him?\\r\\n\\r\\n  \"I could name you a dozen, yes, hundreds, I guess,\\r\\n  Of poor boys who\\'ve patiently climbed to success;\\r\\n  All boys who were down and who struggled alone,\\r\\n  Who\\'d have thought themselves rich if your fortune they\\'d known;\\r\\n  Yet they rose in the world you\\'re so quick to condemn,\\r\\n  And I\\'m asking you now, was the world against them?\"\\r\\n\\r\\n\\r\\n_Edgar A. Guest._\\r\\n\\r\\nFrom \"Just Folks.\"\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nSAY NOT THE STRUGGLE NOUGHT AVAILETH\\r\\n\\r\\n\\r\\nIn any large or prolonged enterprise we are likely to take too limited a\\r\\nview of the progress we are making. The obstacles do not yield at some\\r\\ngiven point; we therefore imagine we have made no headway. The poet here\\r\\nuses three comparisons to show the folly of accepting this hasty and\\r\\npartial evidence. A soldier may think, from the little part of the\\r\\nbattle he can see, that the day is going against him; but by holding his\\r\\nground stoutly he may help his comrades in another quarter to win the\\r\\nvictory. Successive waves may seem to rise no higher on the land, but\\r\\nfar back in swollen creek and inlet is proof that the tide is coming in.\\r\\nAs we look toward the east, we are discouraged at the slowness of\\r\\ndaybreak; but by looking westward we see the whole landscape illumined.\\r\\n\\r\\n\\r\\n  Say not the struggle nought availeth,\\r\\n    The labor and the wounds are vain,\\r\\n  The enemy faints not, nor faileth,\\r\\n    And as things have been they remain.\\r\\n\\r\\n  If hopes were dupes, fears may be liars;\\r\\n    It may be, in yon smoke conceal\\'d,\\r\\n  Your comrades chase e\\'en now the fliers,\\r\\n    And, but for you, possess the field.\\r\\n\\r\\n  For while the tired waves, vainly breaking,\\r\\n    Seem here no painful inch to gain,\\r\\n  Far back, through creeks and inlets making,\\r\\n    Comes silent, flooding in, the main.\\r\\n\\r\\n  And not by eastern windows only,\\r\\n    When daylight comes, comes in the light,\\r\\n  In front, the sun climbs slow, how slowly,\\r\\n    But westward, look, the land is bright.\\r\\n\\r\\n\\r\\n_Arthur Hugh Clough._\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nWORTH WHILE\\r\\n\\r\\n\\r\\nA little boy whom his mother had rebuked for not turning a deaf ear to\\r\\ntemptation protested, with tears, that he had no deaf ear. But\\r\\ntemptation, even when heard, must somehow be resisted. Yea, especially\\r\\nwhen heard! We deserve no credit for resisting it unless it comes to our\\r\\nears like the voice of the siren.\\r\\n\\r\\n\\r\\n  It is easy enough to be pleasant,\\r\\n    When life flows by like a song,\\r\\n  But the man worth while is one who will smile,\\r\\n    When everything goes dead wrong.\\r\\n  For the test of the heart is trouble,\\r\\n    And it always comes with the years,\\r\\n  And the smile that is worth the praises of earth,\\r\\n    Is the smile that shines through tears.\\r\\n\\r\\n  It is easy enough to be prudent,\\r\\n    When nothing tempts you to stray,\\r\\n  When without or within no voice of sin\\r\\n    Is luring your soul away;\\r\\n  But it\\'s only a negative virtue\\r\\n    Until it is tried by fire,\\r\\n  And the life that is worth the honor on earth,\\r\\n    Is the one that resists desire.\\r\\n\\r\\n  By the cynic, the sad, the fallen,\\r\\n    Who had no strength for the strife,\\r\\n  The world\\'s highway is cumbered to-day,\\r\\n    They make up the sum of life.\\r\\n  But the virtue that conquers passion,\\r\\n    And the sorrow that hides in a smile,\\r\\n  It is these that are worth the homage on earth\\r\\n    For we find them but once in a while.\\r\\n\\r\\n\\r\\n_Ella Wheeler Wilcox._\\r\\n\\r\\nFrom \"Poems of Sentiment.\"\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nHOPE\\r\\n\\r\\n\\r\\nGloom and despair are really ignorance in another form. They fail to\\r\\nreckon with the fact that what appears to be baneful often turns out to\\r\\nbe good. Lincoln lost the senatorship to Douglas and thought he had\\r\\nended his career; had he won the contest, he might have remained only a\\r\\nsenator. Life often has surprise parties for us. Things come to us\\r\\nmasked in gloom and black; but Time, the revealer, strips off the\\r\\ndisguise, and lo, what we have is blessings.\\r\\n\\r\\n\\r\\n  Never go gloomy, man with a mind,\\r\\n    Hope is a better companion than fear;\\r\\n  Providence, ever benignant and kind,\\r\\n    Gives with a smile what you take with a tear;\\r\\n      All will be right,\\r\\n      Look to the light.\\r\\n  Morning was ever the daughter of night;\\r\\n  All that was black will be all that is bright,\\r\\n     Cheerily, cheerily, then cheer up.\\r\\n\\r\\n  Many a foe is a friend in disguise,\\r\\n    Many a trouble a blessing most true,\\r\\n  Helping the heart to be happy and wise,\\r\\n    With love ever precious and joys ever new.\\r\\n      Stand in the van,\\r\\n      Strike like a man!\\r\\n  This is the bravest and cleverest plan;\\r\\n  Trusting in God while you do what you can.\\r\\n     Cheerily, cheerily, then cheer up.\\r\\n\\r\\n\\r\\n_Anonymous._\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nI\\'M GLAD\\r\\n\\r\\n\\r\\n  I\\'m glad the sky is painted blue;\\r\\n    And the earth is painted green;\\r\\n  And such a lot of nice fresh air\\r\\n    All sandwiched in between.\\r\\n\\r\\n\\r\\n_Anonymous._\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nTHE CHAMBERED NAUTILUS\\r\\n\\r\\n\\r\\nThe nautilus is a small mollusk that creeps upon the bottom of the sea,\\r\\nthough it used to be supposed to swim, or even to spread a kind of sail\\r\\nso that the wind might drive it along the surface. What interests us in\\r\\nthis poem is the way the nautilus _grows_. Just as a tree when sawed\\r\\ndown has the record of its age in the number of its rings, so does the\\r\\nnautilus measure its age by the ever-widening compartments of its shell.\\r\\nThese it has successively occupied. The poet, looking upon the now empty\\r\\nshell, thinks of human life as growing in the same way. We advance from\\r\\none state of being to another, each nobler than the one which preceded\\r\\nit, until the spirit leaves its shell altogether and attains a gloriou'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_document.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `VectorStoreIndex` in LlamaIndex can be created in two ways: `from_documents` and `from_vector_store`.\n",
    "\n",
    "- `from_documents`: when you have a set of documents that you want to index. This method takes these documents, computes their embeddings, and stores them in the vector store. \n",
    "\n",
    "- `from_vector_store`: when you already have computed embeddings that are stored in an external vector store (like Qdrant). This method connects to the external vector store and uses the pre-computed embeddings for the index. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150dc2bf6a88452896e436e002874ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9785c36f3f4b44912397fbf61acbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    # remember, you must pass a list of documents!\n",
    "    [partial_document], \n",
    "    embed_model=embed_v3,\n",
    "    show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, you can also build an index over a **list of `Node` objects**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4a6bc5298b485a82b42764096d29a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# instantiate a node parser\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=16,\n",
    "    paragraph_separator=\"\\n\\n\\n\\n\",\n",
    ")\n",
    "\n",
    "# pass a list of documents to the node paraser\n",
    "nodes = splitter.get_nodes_from_documents([partial_document])\n",
    "\n",
    "# create the index from the nodes\n",
    "index_from_nodes = VectorStoreIndex(\n",
    "    nodes,\n",
    "    embed_model=embed_v3,\n",
    "    show_progress=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build on this pattern in the next lesson, where we'll store and persist our index for future use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lil_llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
